"""
ML Orchestrator for Production IDS
Coordinates all ML components and provides unified prediction interface.

Integrates:
- Feature Engineering (47-dim feature extraction)
- Ensemble Classifier (RF/XGB/Isolation Forest)
- Deep Learning Detector (LSTM sequences)
"""
import numpy as np
from typing import List, Dict, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import os

from models.flow import NetworkFlow
from services.ml.feature_engineering import FeatureEngineering, FlowFeatures
from services.ml.ensemble_classifier import EnsembleClassifier, EnsemblePrediction
from services.ml.deep_learning_detector import DeepLearningDetector, DLPrediction


@dataclass
class MLAlert:
    """Alert generated by ML subsystem"""
    alert_id: str
    source_ip: str
    dest_ip: str
    attack_type: str
    confidence: float
    severity: str
    
    # Model attribution
    ensemble_prediction: Optional[str] = None
    ensemble_confidence: float = 0.0
    sequence_prediction: Optional[str] = None
    sequence_confidence: float = 0.0
    
    # Explainability
    top_features: List[Tuple[str, float]] = field(default_factory=list)
    explanation: str = ""
    
    # Context
    flow_features: Optional[FlowFeatures] = None
    timestamp: datetime = field(default_factory=datetime.now)
    
    # MITRE ATT&CK mapping (placeholder for threat intel integration)
    mitre_techniques: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for API response"""
        return {
            'alert_id': self.alert_id,
            'source_ip': self.source_ip,
            'dest_ip': self.dest_ip,
            'attack_type': self.attack_type,
            'confidence': round(self.confidence, 3),
            'severity': self.severity,
            'ensemble_prediction': self.ensemble_prediction,
            'ensemble_confidence': round(self.ensemble_confidence, 3),
            'sequence_prediction': self.sequence_prediction,
            'sequence_confidence': round(self.sequence_confidence, 3),
            'top_features': self.top_features[:5],
            'explanation': self.explanation,
            'mitre_techniques': self.mitre_techniques,
            'timestamp': self.timestamp.isoformat()
        }


class MLOrchestrator:
    """
    ML Orchestrator for Production IDS.
    
    Coordinates feature extraction, ensemble classification, and
    sequence-based deep learning detection to provide unified
    ML-powered intrusion detection.
    
    Flow:
    1. Extract features from network flows
    2. Run ensemble classifier for immediate classification
    3. Aggregate flows into sequences for LSTM analysis
    4. Combine predictions with confidence-weighted voting
    5. Generate explainable alerts
    """
    
    # Severity thresholds
    SEVERITY_THRESHOLDS = {
        'critical': 0.9,
        'high': 0.75,
        'medium': 0.5,
        'low': 0.25
    }
    
    # MITRE ATT&CK mappings for attack types
    MITRE_MAPPINGS = {
        'port_scan': ['T1046'],  # Network Service Discovery
        'brute_force': ['T1110'],  # Brute Force
        'icmp_flood': ['T1498'],  # Network Denial of Service
        'lateral_movement': ['T1021'],  # Remote Services
        'policy_violation': ['T1078'],  # Valid Accounts
        'data_exfiltration': ['T1048'],  # Exfiltration Over Alternative Protocol
        'c2_beacon': ['T1071'],  # Application Layer Protocol
        'dns_tunneling': ['T1071.004'],  # DNS
        'arp_spoof': ['T1557']  # Man-in-the-Middle
    }
    
    def __init__(self, model_dir: str = "models"):
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
        
        # Initialize ML components
        self.feature_engine = FeatureEngineering()
        self.ensemble = EnsembleClassifier(model_dir)
        self.dl_detector = DeepLearningDetector()
        
        # Alert tracking
        self.alerts: List[MLAlert] = []
        self.alert_counter = 0
        
        # Flow buffer for batch processing
        self.flow_buffer: List[NetworkFlow] = []
        self.buffer_limit = 100
        
        # Statistics
        self.stats = {
            'flows_processed': 0,
            'attacks_detected': 0,
            'alerts_generated': 0
        }
    
    def analyze_flow(self, flow: NetworkFlow) -> Optional[MLAlert]:
        """
        Analyze a single network flow.
        
        Args:
            flow: NetworkFlow to analyze
            
        Returns:
            MLAlert if attack detected, None otherwise
        """
        self.stats['flows_processed'] += 1
        
        # Extract features
        features = self.feature_engine.extract_flow_features(flow)
        feature_vector = features.to_numpy().reshape(1, -1)
        
        # Run ensemble classification
        ensemble_pred = self.ensemble.predict_single(feature_vector[0])
        
        # Add to sequence buffer for DL
        sequence_window = self.dl_detector.add_flow_to_buffer(
            flow.source_ip, 
            feature_vector[0],
            getattr(flow, 'start_time', datetime.now())
        )
        
        # Run DL prediction if window is ready
        dl_pred = None
        if sequence_window:
            dl_pred = self.dl_detector.predict_sequence(sequence_window)
        
        # Combine predictions
        combined = self._combine_predictions(
            ensemble_pred, dl_pred, features, flow
        )
        
        if combined.is_attack:
            alert = self._create_alert(flow, features, ensemble_pred, dl_pred)
            self.alerts.append(alert)
            self.stats['attacks_detected'] += 1
            self.stats['alerts_generated'] += 1
            return alert
        
        return None
    
    def analyze_batch(self, flows: List[NetworkFlow]) -> List[MLAlert]:
        """
        Analyze a batch of flows efficiently.
        
        Args:
            flows: List of NetworkFlow objects
            
        Returns:
            List of MLAlert objects for detected attacks
        """
        if not flows:
            return []
        
        self.stats['flows_processed'] += len(flows)
        
        # Batch feature extraction
        features_list = []
        flow_features_map = {}
        for flow in flows:
            ff = self.feature_engine.extract_flow_features(flow)
            features_list.append(ff.to_numpy())
            flow_features_map[id(flow)] = ff
        
        feature_matrix = np.array(features_list)
        
        # Batch ensemble prediction
        ensemble_preds = self.ensemble.predict(feature_matrix)
        
        # Batch DL prediction (windowed)
        dl_preds = self.dl_detector.predict_flows(feature_matrix)
        
        # Generate alerts for attacks
        alerts = []
        for i, (flow, ens_pred) in enumerate(zip(flows, ensemble_preds)):
            # Get corresponding DL prediction (may be fewer due to windowing)
            dl_idx = i // max(1, (self.dl_detector.SEQUENCE_LENGTH // 2))
            dl_pred = dl_preds[dl_idx] if dl_preds and dl_idx < len(dl_preds) else None
            
            combined = self._combine_predictions(
                ens_pred, dl_pred, flow_features_map[id(flow)], flow
            )
            
            if combined.is_attack:
                alert = self._create_alert(
                    flow, flow_features_map[id(flow)], ens_pred, dl_pred
                )
                alerts.append(alert)
                self.alerts.append(alert)
        
        self.stats['attacks_detected'] += len(alerts)
        self.stats['alerts_generated'] += len(alerts)
        
        return alerts
    
    def _combine_predictions(self, 
                             ens_pred: EnsemblePrediction,
                             dl_pred: Optional[DLPrediction],
                             features: FlowFeatures,
                             flow: NetworkFlow) -> Any:
        """
        Combine ensemble and DL predictions using weighted voting.
        
        Ensemble gets 60% weight, DL gets 40% when both available.
        """
        @dataclass
        class CombinedPrediction:
            attack_type: str
            confidence: float
            is_attack: bool
        
        # If only ensemble available
        if dl_pred is None:
            return CombinedPrediction(
                attack_type=ens_pred.attack_type,
                confidence=ens_pred.confidence,
                is_attack=ens_pred.is_attack
            )
        
        # Weighted combination
        ens_weight = 0.6
        dl_weight = 0.4
        
        combined_confidence = (
            ens_pred.confidence * ens_weight + 
            dl_pred.confidence * dl_weight
        )
        
        # Take attack type from higher confidence model
        if ens_pred.confidence >= dl_pred.confidence:
            attack_type = ens_pred.attack_type
        else:
            attack_type = dl_pred.attack_type
        
        # Attack if either predicts attack with decent confidence
        is_attack = (
            (ens_pred.is_attack and ens_pred.confidence > 0.5) or
            (dl_pred.is_attack and dl_pred.confidence > 0.5)
        )
        
        return CombinedPrediction(
            attack_type=attack_type,
            confidence=combined_confidence,
            is_attack=is_attack
        )
    
    def _create_alert(self,
                      flow: NetworkFlow,
                      features: FlowFeatures,
                      ens_pred: EnsemblePrediction,
                      dl_pred: Optional[DLPrediction]) -> MLAlert:
        """Create an ML alert with full context and explanation"""
        self.alert_counter += 1
        
        # Determine final attack type and confidence
        if dl_pred and dl_pred.is_attack and dl_pred.confidence > ens_pred.confidence:
            attack_type = dl_pred.attack_type
            confidence = (ens_pred.confidence * 0.6 + dl_pred.confidence * 0.4)
        else:
            attack_type = ens_pred.attack_type
            confidence = ens_pred.confidence
        
        # Determine severity
        severity = 'low'
        for sev, threshold in self.SEVERITY_THRESHOLDS.items():
            if confidence >= threshold:
                severity = sev
                break
        
        # Get MITRE techniques
        mitre = self.MITRE_MAPPINGS.get(attack_type, [])
        
        # Generate explanation
        explanation = self._generate_explanation(
            flow, features, ens_pred, dl_pred, attack_type
        )
        
        return MLAlert(
            alert_id=f"ML-{self.alert_counter:06d}",
            source_ip=flow.source_ip,
            dest_ip=flow.dest_ip,
            attack_type=attack_type,
            confidence=confidence,
            severity=severity,
            ensemble_prediction=ens_pred.attack_type,
            ensemble_confidence=ens_pred.confidence,
            sequence_prediction=dl_pred.attack_type if dl_pred else None,
            sequence_confidence=dl_pred.confidence if dl_pred else 0.0,
            top_features=ens_pred.top_features,
            explanation=explanation,
            flow_features=features,
            mitre_techniques=mitre
        )
    
    def _generate_explanation(self,
                              flow: NetworkFlow,
                              features: FlowFeatures,
                              ens_pred: EnsemblePrediction,
                              dl_pred: Optional[DLPrediction],
                              attack_type: str) -> str:
        """Generate human-readable explanation for the alert"""
        explanations = {
            'port_scan': f"Port scanning detected from {flow.source_ip}. "
                        f"Multiple ports were probed on {flow.dest_ip}. "
                        f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'brute_force': f"Brute force attack detected from {flow.source_ip}. "
                          f"Multiple connection attempts to {flow.dest_ip}:{flow.dest_port}. "
                          f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'icmp_flood': f"ICMP flood detected from {flow.source_ip}. "
                         f"High packet rate: {features.flow_packets_per_second:.0f} pps. "
                         f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'lateral_movement': f"Lateral movement detected from {flow.source_ip}. "
                               f"Internal host accessing multiple destinations. "
                               f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'data_exfiltration': f"Data exfiltration suspected from {flow.source_ip}. "
                                f"High outbound data volume with entropy: {features.entropy_score:.2f}. "
                                f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'c2_beacon': f"C2 beacon pattern detected from {flow.source_ip}. "
                        f"Periodic connection pattern to {flow.dest_ip}. "
                        f"Sequence confidence: {dl_pred.confidence if dl_pred else 0:.0%}",
            
            'dns_tunneling': f"DNS tunneling suspected from {flow.source_ip}. "
                            f"Unusual DNS query patterns detected. "
                            f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'policy_violation': f"Policy violation from {flow.source_ip}. "
                               f"Unauthorized access to {features.dest_is_admin and 'admin zone' or 'server zone'}. "
                               f"Ensemble confidence: {ens_pred.confidence:.0%}",
            
            'arp_spoof': f"ARP spoofing detected from {flow.source_ip}. "
                        f"MAC address anomaly on network. "
                        f"Ensemble confidence: {ens_pred.confidence:.0%}",
        }
        
        return explanations.get(
            attack_type, 
            f"Unknown attack type '{attack_type}' detected from {flow.source_ip} "
            f"with {ens_pred.confidence:.0%} confidence."
        )
    
    def get_alerts(self, limit: int = 100) -> List[Dict]:
        """Get recent alerts as dictionaries"""
        return [alert.to_dict() for alert in self.alerts[-limit:]]
    
    def get_stats(self) -> Dict:
        """Get ML processing statistics"""
        return {
            **self.stats,
            'ensemble_info': self.ensemble.get_model_info(),
            'dl_info': self.dl_detector.get_model_info(),
            'feature_count': self.feature_engine.num_features
        }
    
    def clear_alerts(self) -> None:
        """Clear all alerts"""
        self.alerts.clear()
        self.alert_counter = 0
    
    def train_models(self, flows: List[NetworkFlow], labels: List[str]) -> Dict:
        """
        Train all ML models on labeled data.
        
        Args:
            flows: List of NetworkFlow objects
            labels: List of attack type labels
            
        Returns:
            Training metrics dictionary
        """
        # Extract features
        features = self.feature_engine.extract_batch_features(flows)
        features_normalized = self.feature_engine.normalize_features(features, fit=True)
        
        # Train ensemble
        ensemble_metrics = self.ensemble.fit(
            features_normalized, 
            np.array(labels),
            self.feature_engine.feature_names
        )
        
        # Prepare sequences for DL training
        # Create sliding windows of flows
        sequences = []
        seq_labels = []
        seq_len = self.dl_detector.SEQUENCE_LENGTH
        
        for i in range(0, len(features) - seq_len, seq_len // 2):
            sequences.append(features_normalized[i:i + seq_len])
            # Use most common label in window
            window_labels = labels[i:i + seq_len]
            seq_labels.append(max(set(window_labels), key=window_labels.count))
        
        if sequences:
            sequences_array = np.array(sequences)
            dl_metrics = self.dl_detector.fit(sequences_array, np.array(seq_labels))
        else:
            dl_metrics = {'error': 'Not enough data for sequence training'}
        
        return {
            'ensemble': ensemble_metrics,
            'deep_learning': dl_metrics,
            'n_flows': len(flows),
            'n_sequences': len(sequences)
        }
    
    def save_models(self) -> Dict[str, str]:
        """Save all models to disk"""
        paths = {}
        
        ensemble_path = self.ensemble.save()
        paths['ensemble'] = ensemble_path
        
        dl_path = os.path.join(self.model_dir, 'dl_detector')
        self.dl_detector.save(dl_path)
        paths['deep_learning'] = dl_path
        
        return paths
    
    def load_models(self, paths: Dict[str, str]) -> None:
        """Load models from disk"""
        if 'ensemble' in paths:
            self.ensemble.load(paths['ensemble'])
        if 'deep_learning' in paths:
            self.dl_detector.load(paths['deep_learning'])
